import pandas as pd
import numpy as np
import re
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
import os 
from sklearn.model_selection import GridSearchCV
from sklearn.externals import joblib 
from nltk.stem import PorterStemmer
import operator 
from underthesea import word_tokenize

import codecs
path_nag = 'nag.txt'
path_pos = 'pos.txt'

with codecs.open(path_nag, 'r', encoding='UTF-8') as f:
    nag = f.readlines()
nag_list = [n.replace('\n', '') for n in nag]

with codecs.open(path_pos, 'r', encoding='UTF-8') as f:
    pos = f.readlines()
pos_list = [n.replace('\n', '') for n in pos]

def predict(text):
    
    """This function predicts if a sentence is sarcastic or not."""
    
    data = text
        
    data = re.sub(r'([A-Z])\1+', lambda m: m.group(1).upper(), data, flags=re.IGNORECASE)
    data = data.lower()
    replace_list = {
        'รฒa': 'oร', 'รณa': 'oรก', 'แปa': 'oแบฃ', 'รตa': 'oรฃ', 'แปa': 'oแบก', 'รฒe': 'oรจ', 'รณe': 'oรฉ','แปe': 'oแบป',
        'รตe': 'oแบฝ', 'แปe': 'oแบน', 'รนy': 'uแปณ', 'รบy': 'uรฝ', 'แปงy': 'uแปท', 'ลฉy': 'uแปน','แปฅy': 'uแปต', 'uแบฃ': 'แปงa',
        'aฬ': 'แบฃ', 'รดฬ': 'แป', 'uยด': 'แป','รดฬ': 'แป', 'รดฬ': 'แป', 'รดฬ': 'แป', 'รขฬ': 'แบฅ', 'รขฬ': 'แบซ', 'รขฬ': 'แบฉ',
        'รขฬ': 'แบง', 'oฬ': 'แป', 'รชฬ': 'แป','รชฬ': 'แป', 'ฤฬ': 'แบฏ', 'uฬ': 'แปง', 'รชฬ': 'แบฟ', 'ฦกฬ': 'แป', 'iฬ': 'แป',
        'eฬ': 'แบป', 'รk': u' ร ','aห': 'ร', 'iห': 'รฌ', 'ฤยด': 'แบฏ','ฦฐฬ': 'แปญ', 'eห': 'แบฝ', 'yห': 'แปน', 'aยด': 'รก',
        'รด kรชi': ' ok ', 'okie': ' ok ', ' o kรช ': ' ok ', ':)' : 'positive', ':(' : 'negative',
        'okey': ' ok ', 'รดkรช': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okรช':' ok ',
        ' tks ': u' cรกm ฦกn ', 'thks': u' cรกm ฦกn ', 'thanks': u' cรกm ฦกn ', 'ths': u' cรกm ฦกn ', 'thank': u' cรกm ฦกn ',
        'โญ': 'star ', '*': 'star ', '๐': 'star ', '๐': u' positive ',
        'kg ': u' khรดng ','not': u' khรดng ', u' kg ': u' khรดng ', '"k ': u' khรดng ',' kh ':u' khรดng ','kรด':u' khรดng ','hok':u' khรดng ',' kp ': u' khรดng phแบฃi ',u' kรด ': u' khรดng ', '"ko ': u' khรดng ', u' ko ': u' khรดng ', u' k ': u' khรดng ', 'khong': u' khรดng ', u' hok ': u' khรดng ',
        'he he': ' positive ','hehe': ' positive ','hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',
        ' lol ': ' nagative ',' cc ': ' nagative ','cute': u' dแป thฦฐฦกng ','huhu': ' nagative ', ' vs ': u' vแปi ', 'wa': ' quรก ', 'wรก': u' quรก', 'j': u' gรฌ ', 'โ': ' ',
        ' sz ': u' cแปก ', 'size': u' cแปก ', u' ฤx ': u' ฤฦฐแปฃc ', 'dk': u' ฤฦฐแปฃc ', 'dc': u' ฤฦฐแปฃc ', 'ฤk': u' ฤฦฐแปฃc ',
        'ฤc': u' ฤฦฐแปฃc ','authentic': u' chuแบฉn chรญnh hรฃng ',u' aut ': u' chuแบฉn chรญnh hรฃng ', u' auth ': u' chuแบฉn chรญnh hรฃng ', 'thick': u' positive ', 'store': u' cแปญa hรng ',
        'shop': u' cแปญa hรng ', 'sp': u' sแบฃn phแบฉm ', 'gud': u' tแปt ','god': u' tแปt ','wel done':' tแปt ', 'good': u' tแปt ', 'gรบt': u' tแปt ',
        'sแบฅu': u' xแบฅu ','gut': u' tแปt ', u' tot ': u' tแปt ', u' nice ': u' tแปt ', 'perfect': 'rแบฅt tแปt', 'bt': u' bรฌnh thฦฐแปng ',
        'time': u' thแปi gian ', 'qรก': u' quรก ', u' ship ': u' giao hรng ', u' m ': u' mรฌnh ', u' mik ': u' mรฌnh ',
        'รชฬ': 'แป', 'product': 'sแบฃn phแบฉm', 'quality': 'chแบฅt lฦฐแปฃng','chat':' chแบฅt ', 'excelent': 'hoรn hแบฃo', 'bad': 'tแป','fresh': ' tฦฐฦกi ','sad': ' tแป ',
        'date': u' hแบกn sแปญ dแปฅng ', 'hsd': u' hแบกn sแปญ dแปฅng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hรng ',u' sรญp ': u' giao hรng ',
        'beautiful': u' ฤแบนp tuyแปt vแปi ', u' tl ': u' trแบฃ lแปi ', u' r ': u' rแปi ', u' shopE ': u' cแปญa hรng ',u' order ': u' ฤแบทt hรng ',
        'chแบฅt lg': u' chแบฅt lฦฐแปฃng ',u' sd ': u' sแปญ dแปฅng ',u' dt ': u' ฤiแปn thoแบกi ',u' nt ': u' nhแบฏn tin ',u' tl ': u' trแบฃ lแปi ',u' sรi ': u' xรi ',u'bjo':u' bao giแป ',
        'thik': u' thรญch ',u' sop ': u' cแปญa hรng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rแบฅt ',u'quแบฃ ng ':u' quแบฃng  ',
        'dep': u' ฤแบนp ',u' xau ': u' xแบฅu ','delicious': u' ngon ', u'hรg': u' hรng ', u'qแปงa': u' quแบฃ ',
        'iu': u' yรชu ','fake': u' giแบฃ mแบกo ', 'trl': 'trแบฃ lแปi', '><': u' positive ', 'khรดng dแป': 'ngon', 'khรดng xแบฅu': 'ฤแบนp',
        ' por ': u' tแป ',' poor ': u' tแป ', 'ib':u' nhแบฏn tin ', 'rep':u' trแบฃ lแปi ',u'fback':' feedback ','fedback':' feedback ',
        #dฦฐแปi 3* quy vแป 1*, trรชn 3* quy vแป 5*
        '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ',
        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ',
        '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ', 'khรดng lรm tรดi thแบฅt vแปng': 'positive', 'khรดng ngon': 'dแป', 'khรดng vui': 'buแปn', 'khรดng tแป': 'tแปt', 'khรดng buแปn' : 'vui'
    }
    for k ,v in replace_list.items():
      data = data.replace(k,v)
    data = data.replace(",", " ").replace(".", " ") \
        .replace(";", " ").replace("โ", " ") \
        .replace(":", " ").replace("โ", " ") \
        .replace('"', " ").replace("'", " ") \
        .replace("!", " ").replace("?", " ") \
        .replace("-", " ").replace("?", " ")      
    data = data.strip()

    data = word_tokenize(data, format='text')

    datas = data.split()
    len_ = len(datas)
    datas = [t.replace('_', ' ') for t in datas]
    for i in range(len_):
      cp_data = datas[i]
    if cp_data in pos_list:
      datas.append('positive')
    elif cp_data in nag_list:
      datas.append('nagative')
    data = u' '.join(datas)

    s = []
    
    s.append(data)
    
    with open('tfidf.pkl', 'rb') as f:
        vectorizer = joblib.load(f)
    
    with open('saved_model.pkl', 'rb') as f:
        model = joblib.load(f)
    
    data = vectorizer.transform(s).toarray()
        
    prediction = model.predict(data)

    return int(prediction[0])

